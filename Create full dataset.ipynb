{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "coin_ids = {\n",
    "    'Bitcoin': 1442,\n",
    "    'Ripple': 1444,\n",
    "    'Ethereum': 1443,\n",
    "    'Bitcoin Cash': 1445,\n",
    "    'Bitcoin Gold': 1456,\n",
    "    'Cardano': 1446,\n",
    "    'Dash': 1453,\n",
    "    'Dogecoin': 1477,\n",
    "    'Eos': 1452,\n",
    "    'Ethereum Classic': 1457,\n",
    "    'Iota': 1451,\n",
    "    'Lisk': 1460,\n",
    "    'Litecoin': 1448,\n",
    "    'Monero': 1454,\n",
    "    'NEMcoin': 1447,\n",
    "    'Neo': 1449,\n",
    "    'Stellar': 1450,\n",
    "    'Tether': 1474,\n",
    "    'Tron': 1455,\n",
    "    'Zcash': 1465,\n",
    "}\n",
    "\n",
    "id_coins = {v: k for k, v in coin_ids.items()}\n",
    "\n",
    "### load data:\n",
    "\n",
    "iterator_full_data = pd.read_csv('data/datathon.csv', iterator=True, chunksize=100000, parse_dates=['time'])\n",
    "subset_full_data = pd.concat([chunk[chunk.refID_coin.isin(coin_ids.values())] for chunk in iterator_full_data])\n",
    "subset_full_data = subset_full_data.replace({'refID_coin': id_coins})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing value issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There are some duplicate rows, as well as some rows that should exist, but don't:\n",
    "subset_full_data[subset_full_data[['time', 'refID_coin']].duplicated()].shape\n",
    "\n",
    "first_period = subset_full_data.time.min()\n",
    "last_period = subset_full_data.time.max()\n",
    "all_periods = pd.date_range(start=first_period, end=last_period, freq='5min')\n",
    "all_currencies = subset_full_data.refID_coin.unique()\n",
    "full_index = pd.MultiIndex.from_product([all_periods, all_currencies])\n",
    "subset_full_data = (subset_full_data\n",
    "                    .drop_duplicates(subset=['time', 'refID_coin'])\n",
    "                    .set_index(['time', 'refID_coin'])\n",
    "                    .reindex(full_index, fill_value = np.nan)\n",
    "                    .reset_index()\n",
    "                    .rename({'level_0': 'time', 'level_1': 'refID_coin'}, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add market cap percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill missing values:\n",
    "numeric_cols = ['price', 'marketCap', 'CirculatingSupply', 'Volume24h', 'Movement1h', 'Movement24h']\n",
    "\n",
    "subset_full_data[numeric_cols] = subset_full_data.groupby('refID_coin')[numeric_cols].transform(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "### Calculate marketCap % for each currency by period\n",
    "\n",
    "market_caps = subset_full_data[['time', 'refID_coin', 'marketCap']]\n",
    "market_caps = market_caps.pivot(index='time', columns='refID_coin', values='marketCap')\n",
    "market_caps['total_market_cap'] = market_caps.sum(axis=1)\n",
    "\n",
    "for currency in coin_ids.keys():\n",
    "    market_caps[currency] = market_caps[currency] / market_caps['total_market_cap']\n",
    "\n",
    "# market_caps.drop('total_market_cap', axis=1, inplace=True) \n",
    "market_caps.head()\n",
    "\n",
    "### save just in case\n",
    "market_caps.to_csv('data/market_caps_by_period.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpivot market caps, so that I can join them to total_subset_data\n",
    "I realize that's ugly, but I think it's not possible to be cleaner - see https://github.com/pandas-dev/pandas/issues/17676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivoted_market_caps = market_caps.reset_index()\\\n",
    "                        .drop(columns = ['total_market_cap'], axis=1)\\\n",
    "                        .melt(id_vars = ['time'], value_vars=subset_full_data.refID_coin.unique().tolist())\\\n",
    "                        .rename({'value': 'percent_market_cap'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(values):\n",
    "    values /= sum(values)\n",
    "    return - sum(values * np.log2(values.astype('float64'))) \n",
    "market_caps['market_entropy'] = market_caps.apply(lambda x: calculate_entropy(x[coin_ids.keys()]), axis=1)\n",
    "market_caps = market_caps.reset_index()[['time', 'market_entropy', 'total_market_cap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_full_data = pd.merge(subset_full_data, unpivoted_market_caps, how = 'outer', on = ['time', 'refID_coin'])\n",
    "subset_full_data = pd.merge(subset_full_data, market_caps, how = 'left', on = ['time'])\n",
    "subset_full_data.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create moving variances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = \"marketCap|CirculatingSupply|Volume24h|market_entropy|total_market_cap|price\"\n",
    "log_cols = subset_full_data.filter(regex = regex).columns\n",
    "subset_full_data.loc[:, log_cols] = np.log(subset_full_data.loc[:, log_cols].values+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cols = ['total_market_cap']\n",
    "all_numeric_cols = [] + numeric_cols\n",
    "for column in var_cols:\n",
    "    for center_of_mass in [72]:\n",
    "        new_col_name = column + '_MA_VAR_' + str(center_of_mass)\n",
    "        all_numeric_cols.append(new_col_name)\n",
    "        ma = subset_full_data.groupby(\"refID_coin\", as_index = False).apply(lambda x: x[column].ewm(com=center_of_mass).std())\n",
    "        subset_full_data[new_col_name] = ma.reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create moving averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_cols = ['price', 'CirculatingSupply', 'percent_market_cap']\n",
    "low_priority_cols = ['market_entropy', 'total_market_cap', 'market_cap']\n",
    "all_numeric_cols = [] + numeric_cols\n",
    "for column in high_priority_cols:\n",
    "    for center_of_mass in [2, 4, 12, 24, 72]:\n",
    "        new_col_name = column + '_MA_' + str(window)\n",
    "        all_numeric_cols.append(new_col_name)\n",
    "        ma = subset_full_data.groupby(\"refID_coin\", as_index = False).apply(lambda x: x[column].ewm(com=center_of_mass).mean())\n",
    "        subset_full_data[new_col_name] = ma.reset_index(level=0, drop=True)\n",
    "        \n",
    "for column in high_priority_cols:\n",
    "    for center_of_mass in [2, 4]:\n",
    "        new_col_name = column + '_MA_' + str(window)\n",
    "        all_numeric_cols.append(new_col_name)\n",
    "        ma = subset_full_data.groupby(\"refID_coin\", as_index = False).apply(lambda x: x[column].ewm(com=center_of_mass).mean())\n",
    "        subset_full_data[new_col_name] = ma.reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_full_data['target'] = subset_full_data.groupby(['refID_coin'])['price'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add price change trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for com in [1,2,4,6,12, 24, 48]:\n",
    "    subset_full_data['trend_price_' + str(com)] = subset_full_data.groupby(\"refID_coin\", as_index = False)\\\n",
    "        .apply(lambda x: (x.target - x.price).ewm(com=com).std())\\\n",
    "        .reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_full_data.to_csv('data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test_date = '2018-02-19'\n",
    "crypto = 'Ripple'\n",
    "subset = subset_full_data[(subset_full_data.refID_coin == 'Ripple') &\n",
    "                          (subset_full_data.time >= start_test_date)]\n",
    "subset = subset.iloc[0:3168][['time', 'refID_coin', 'price']]\n",
    "subset.iloc[2880:, 2] = np.nan\n",
    "subset.to_csv('data/test/test_01.csv')\n",
    "\n",
    "start_test_date = '2018-03-01'\n",
    "crypto = 'Ethereum'\n",
    "subset = subset_full_data[(subset_full_data.refID_coin == 'Ripple') &\n",
    "                          (subset_full_data.time >= start_test_date)]\n",
    "subset = subset.iloc[0:3168][['time', 'refID_coin', 'price']]\n",
    "subset.iloc[2880:, 2] = np.nan\n",
    "subset.to_csv('data/test/test_02.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
